{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File(\"./dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the full function for loading this data\n",
    "def load():\n",
    "    f = h5py.File(\"./dataset.h5\")\n",
    "    x = f['x'].value\n",
    "    y = f['y'].value\n",
    "    f.close()\n",
    "    \n",
    "    x_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=100)\n",
    "    \n",
    "    # Making the data channel last\n",
    "    # 部分圖片的儲存是 (channel ,[height][width] ) 的方法儲存，為了修正，需要調用rollaxis\n",
    "    x_train = np.rollaxis(x_train, 1, 4)\n",
    "    x_test = np.rollaxis(x_test, 1, 4)\n",
    "    \n",
    "    # Normalizing data\n",
    "    x_train = x_train  / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "   \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shengwei\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1 neural softmax\n",
    "#y_test_List = [ y_test[:,i].reshape(len(y_test),1) for i in range(num_classes)]\n",
    "#y_train_List = [ y_train[:,i].reshape(len(y_train),1) for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2 neural softmax\n",
    "y_test_List = []\n",
    "for i in range(num_classes):\n",
    "    new_list = []\n",
    "    for ele in y_test[:,i] :\n",
    "        other_class = 0 if ele == 1 else 1\n",
    "        new_ele = [ele,other_class]\n",
    "        new_list.append(new_ele)\n",
    "    y_test_List.append(np.array(new_list))\n",
    "y_train_List = []\n",
    "for i in range(num_classes):\n",
    "    new_list = []\n",
    "    for ele in y_train[:,i] :\n",
    "        other_class = 0 if ele == 1 else 1\n",
    "        new_ele = [ele,other_class]\n",
    "        new_list.append(new_ele)\n",
    "    y_train_List.append(np.array(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_List[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_List[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_List[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def multitask_loss(y_true, y_pred):\n",
    "# Avoid divide by 0\n",
    "    #keras.backend.clip(x, min_value, max_value)\n",
    "        # x is a tensor\n",
    "        # this function will return a tensor\n",
    "        # clip will made the value in tensor within min and max value\n",
    "        # use it with epsilon() can help make the value within 0~1 but not 0, so it can avoid divide by 0\n",
    "    #keras.backend.epsilon()\n",
    "        #return a float which is very small \n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "# Multi-task loss\n",
    "    # the formule shows below\n",
    "    return K.mean(K.sum(- y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential # for buliding the model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input# for fullconnection layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation # for CNN\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "img_rows, img_cols = 100, 100\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#share layers\n",
    "In_layer = Input(shape=(img_rows, img_cols, channels))\n",
    "\n",
    "C_L_1_1 = Conv2D(32, kernel_size=(3, 3),padding='same',activation = 'relu')(In_layer)\n",
    "C_L_1_2 = Conv2D(32, kernel_size=(3, 3),padding='same',activation = 'relu')(C_L_1_1)\n",
    "MP_L_1 = MaxPooling2D(pool_size=(2, 2))(C_L_1_2)\n",
    "DO_L_1 = Dropout(0.25)(MP_L_1)\n",
    "\n",
    "C_L_2_1 = Conv2D(32, kernel_size=(3, 3),padding='same',activation = 'relu')(DO_L_1)\n",
    "C_L_2_2 = Conv2D(32, kernel_size=(3, 3),padding='same',activation = 'relu')(C_L_2_1)\n",
    "MP_L_2 = MaxPooling2D(pool_size=(2, 2))(C_L_2_2)\n",
    "DO_L_2 = Dropout(0.25)(MP_L_2)\n",
    "\n",
    "Flatten_L = Flatten()(DO_L_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi_task\n",
    "Output_Layers = []\n",
    "for i in range(num_classes):\n",
    "    MTL_L = Dense(2, activation='sigmoid', name='Tag_'+str(i))(Flatten_L)\n",
    "    Output_Layers.append(MTL_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=In_layer, outputs=Output_Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 100, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 100, 32) 9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 50, 50, 32)   9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 50, 50, 32)   9248        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20000)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Tag_0 (Dense)                   (None, 2)            40002       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Tag_1 (Dense)                   (None, 2)            40002       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Tag_2 (Dense)                   (None, 2)            40002       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Tag_3 (Dense)                   (None, 2)            40002       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Tag_4 (Dense)                   (None, 2)            40002       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 228,650\n",
      "Trainable params: 228,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss= \"binary_crossentropy\",\n",
    "              loss_weights=[1., 1., 1., 1., 1.],\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this auc fumction works\n",
    "#add this in model.fit()  :callbacks=callbacks\n",
    "from keras.callbacks import  Callback\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "class roc_auc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict_proba(self.x, verbose=0)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n",
    "        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n",
    "\n",
    "        y_pred_val = self.model.predict_proba(self.x_val, verbose=0)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n",
    "        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n",
    "\n",
    "        print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "callbacks = [roc_auc_callback(training_data=(x_train, [y for y in y_train_List]),validation_data=(x_test, [y for y in y_test_List]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 58s 36ms/step - loss: 1.7573 - Tag_0_loss: 0.2542 - Tag_1_loss: 0.3312 - Tag_2_loss: 0.4957 - Tag_3_loss: 0.1904 - Tag_4_loss: 0.4858 - Tag_0_acc: 0.9028 - Tag_1_acc: 0.8772 - Tag_2_acc: 0.7856 - Tag_3_acc: 0.9303 - Tag_4_acc: 0.8444 - val_loss: 1.7157 - val_Tag_0_loss: 0.3100 - val_Tag_1_loss: 0.4060 - val_Tag_2_loss: 0.4212 - val_Tag_3_loss: 0.1976 - val_Tag_4_loss: 0.3809 - val_Tag_0_acc: 0.8825 - val_Tag_1_acc: 0.8325 - val_Tag_2_acc: 0.8037 - val_Tag_3_acc: 0.9325 - val_Tag_4_acc: 0.8575\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 59s 37ms/step - loss: 1.1932 - Tag_0_loss: 0.1972 - Tag_1_loss: 0.2577 - Tag_2_loss: 0.3794 - Tag_3_loss: 0.1278 - Tag_4_loss: 0.2311 - Tag_0_acc: 0.9237 - Tag_1_acc: 0.8909 - Tag_2_acc: 0.8241 - Tag_3_acc: 0.9534 - Tag_4_acc: 0.9097 - val_loss: 1.7700 - val_Tag_0_loss: 0.2896 - val_Tag_1_loss: 0.4138 - val_Tag_2_loss: 0.4225 - val_Tag_3_loss: 0.2200 - val_Tag_4_loss: 0.4242 - val_Tag_0_acc: 0.8925 - val_Tag_1_acc: 0.8325 - val_Tag_2_acc: 0.8025 - val_Tag_3_acc: 0.9100 - val_Tag_4_acc: 0.8500\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 56s 35ms/step - loss: 1.1727 - Tag_0_loss: 0.2124 - Tag_1_loss: 0.2382 - Tag_2_loss: 0.3557 - Tag_3_loss: 0.1176 - Tag_4_loss: 0.2487 - Tag_0_acc: 0.9166 - Tag_1_acc: 0.8997 - Tag_2_acc: 0.8334 - Tag_3_acc: 0.9613 - Tag_4_acc: 0.9047 - val_loss: 1.7449 - val_Tag_0_loss: 0.2975 - val_Tag_1_loss: 0.3844 - val_Tag_2_loss: 0.4164 - val_Tag_3_loss: 0.2097 - val_Tag_4_loss: 0.4369 - val_Tag_0_acc: 0.8937 - val_Tag_1_acc: 0.8363 - val_Tag_2_acc: 0.8075 - val_Tag_3_acc: 0.9325 - val_Tag_4_acc: 0.8500\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 57s 35ms/step - loss: 1.0634 - Tag_0_loss: 0.1702 - Tag_1_loss: 0.2202 - Tag_2_loss: 0.3592 - Tag_3_loss: 0.1027 - Tag_4_loss: 0.2111 - Tag_0_acc: 0.9375 - Tag_1_acc: 0.9153 - Tag_2_acc: 0.8334 - Tag_3_acc: 0.9616 - Tag_4_acc: 0.9206 - val_loss: 2.0347 - val_Tag_0_loss: 0.3553 - val_Tag_1_loss: 0.4904 - val_Tag_2_loss: 0.4496 - val_Tag_3_loss: 0.2791 - val_Tag_4_loss: 0.4603 - val_Tag_0_acc: 0.8563 - val_Tag_1_acc: 0.8287 - val_Tag_2_acc: 0.7838 - val_Tag_3_acc: 0.9013 - val_Tag_4_acc: 0.8500\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 63s 39ms/step - loss: 1.1027 - Tag_0_loss: 0.1695 - Tag_1_loss: 0.2388 - Tag_2_loss: 0.3224 - Tag_3_loss: 0.1290 - Tag_4_loss: 0.2430 - Tag_0_acc: 0.9466 - Tag_1_acc: 0.9050 - Tag_2_acc: 0.8553 - Tag_3_acc: 0.9497 - Tag_4_acc: 0.9013 - val_loss: 1.8790 - val_Tag_0_loss: 0.3093 - val_Tag_1_loss: 0.3929 - val_Tag_2_loss: 0.4673 - val_Tag_3_loss: 0.2269 - val_Tag_4_loss: 0.4826 - val_Tag_0_acc: 0.8987 - val_Tag_1_acc: 0.8350 - val_Tag_2_acc: 0.7662 - val_Tag_3_acc: 0.9350 - val_Tag_4_acc: 0.8362\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 60s 37ms/step - loss: 1.1005 - Tag_0_loss: 0.1845 - Tag_1_loss: 0.2314 - Tag_2_loss: 0.3322 - Tag_3_loss: 0.1067 - Tag_4_loss: 0.2457 - Tag_0_acc: 0.9319 - Tag_1_acc: 0.9081 - Tag_2_acc: 0.8578 - Tag_3_acc: 0.9616 - Tag_4_acc: 0.8984 - val_loss: 1.8474 - val_Tag_0_loss: 0.3180 - val_Tag_1_loss: 0.4531 - val_Tag_2_loss: 0.4383 - val_Tag_3_loss: 0.2164 - val_Tag_4_loss: 0.4216 - val_Tag_0_acc: 0.8837 - val_Tag_1_acc: 0.8200 - val_Tag_2_acc: 0.7887 - val_Tag_3_acc: 0.9213 - val_Tag_4_acc: 0.8475\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 62s 39ms/step - loss: 0.9372 - Tag_0_loss: 0.1641 - Tag_1_loss: 0.2022 - Tag_2_loss: 0.2899 - Tag_3_loss: 0.1017 - Tag_4_loss: 0.1792 - Tag_0_acc: 0.9425 - Tag_1_acc: 0.9209 - Tag_2_acc: 0.8750 - Tag_3_acc: 0.9638 - Tag_4_acc: 0.9325 - val_loss: 2.5543 - val_Tag_0_loss: 0.3606 - val_Tag_1_loss: 0.4102 - val_Tag_2_loss: 0.6432 - val_Tag_3_loss: 0.2371 - val_Tag_4_loss: 0.9031 - val_Tag_0_acc: 0.8787 - val_Tag_1_acc: 0.8225 - val_Tag_2_acc: 0.6637 - val_Tag_3_acc: 0.9263 - val_Tag_4_acc: 0.7500\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 59s 37ms/step - loss: 0.9337 - Tag_0_loss: 0.1418 - Tag_1_loss: 0.1984 - Tag_2_loss: 0.3013 - Tag_3_loss: 0.0782 - Tag_4_loss: 0.2142 - Tag_0_acc: 0.9519 - Tag_1_acc: 0.9256 - Tag_2_acc: 0.8578 - Tag_3_acc: 0.9775 - Tag_4_acc: 0.9203 - val_loss: 1.8301 - val_Tag_0_loss: 0.3234 - val_Tag_1_loss: 0.3865 - val_Tag_2_loss: 0.4550 - val_Tag_3_loss: 0.2330 - val_Tag_4_loss: 0.4323 - val_Tag_0_acc: 0.8950 - val_Tag_1_acc: 0.8462 - val_Tag_2_acc: 0.8137 - val_Tag_3_acc: 0.9250 - val_Tag_4_acc: 0.8550\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 60s 37ms/step - loss: 0.8765 - Tag_0_loss: 0.1348 - Tag_1_loss: 0.1728 - Tag_2_loss: 0.2807 - Tag_3_loss: 0.0825 - Tag_4_loss: 0.2057 - Tag_0_acc: 0.9466 - Tag_1_acc: 0.9363 - Tag_2_acc: 0.8756 - Tag_3_acc: 0.9756 - Tag_4_acc: 0.9244 - val_loss: 1.8666 - val_Tag_0_loss: 0.3478 - val_Tag_1_loss: 0.3956 - val_Tag_2_loss: 0.4364 - val_Tag_3_loss: 0.2439 - val_Tag_4_loss: 0.4430 - val_Tag_0_acc: 0.8863 - val_Tag_1_acc: 0.8500 - val_Tag_2_acc: 0.7925 - val_Tag_3_acc: 0.9375 - val_Tag_4_acc: 0.8600\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 61s 38ms/step - loss: 0.8227 - Tag_0_loss: 0.1405 - Tag_1_loss: 0.1756 - Tag_2_loss: 0.2782 - Tag_3_loss: 0.0783 - Tag_4_loss: 0.1501 - Tag_0_acc: 0.9472 - Tag_1_acc: 0.9288 - Tag_2_acc: 0.8744 - Tag_3_acc: 0.9734 - Tag_4_acc: 0.9462 - val_loss: 1.8917 - val_Tag_0_loss: 0.3323 - val_Tag_1_loss: 0.3741 - val_Tag_2_loss: 0.4595 - val_Tag_3_loss: 0.2399 - val_Tag_4_loss: 0.4859 - val_Tag_0_acc: 0.8887 - val_Tag_1_acc: 0.8425 - val_Tag_2_acc: 0.7813 - val_Tag_3_acc: 0.9450 - val_Tag_4_acc: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x42937a20>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, [y for y in y_train_List],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          #callbacks=callbacks,\n",
    "          validation_data=(x_test, [y for y in y_test_List]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 62s 39ms/step - loss: 6.4126 - Tag_0_loss: 1.2244 - Tag_1_loss: 1.2294 - Tag_2_loss: 1.5120 - Tag_3_loss: 1.1373 - Tag_4_loss: 1.3094 - Tag_0_acc: 0.7681 - Tag_1_acc: 0.7662 - Tag_2_acc: 0.7012 - Tag_3_acc: 0.7713 - Tag_4_acc: 0.7237 - val_loss: 5.5938 - val_Tag_0_loss: 1.0995 - val_Tag_1_loss: 1.0082 - val_Tag_2_loss: 1.0643 - val_Tag_3_loss: 0.8160 - val_Tag_4_loss: 1.6058 - val_Tag_0_acc: 0.7900 - val_Tag_1_acc: 0.7625 - val_Tag_2_acc: 0.7425 - val_Tag_3_acc: 0.8000 - val_Tag_4_acc: 0.4650\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 64s 40ms/step - loss: 4.8695 - Tag_0_loss: 0.8994 - Tag_1_loss: 1.0026 - Tag_2_loss: 1.1562 - Tag_3_loss: 0.7299 - Tag_4_loss: 1.0814 - Tag_0_acc: 0.8100 - Tag_1_acc: 0.7444 - Tag_2_acc: 0.7044 - Tag_3_acc: 0.8469 - Tag_4_acc: 0.7650 - val_loss: 5.1022 - val_Tag_0_loss: 0.8619 - val_Tag_1_loss: 1.1012 - val_Tag_2_loss: 1.2558 - val_Tag_3_loss: 0.8611 - val_Tag_4_loss: 1.0222 - val_Tag_0_acc: 0.8200 - val_Tag_1_acc: 0.7600 - val_Tag_2_acc: 0.6375 - val_Tag_3_acc: 0.8225 - val_Tag_4_acc: 0.8175\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 64s 40ms/step - loss: 4.2301 - Tag_0_loss: 0.7714 - Tag_1_loss: 0.8422 - Tag_2_loss: 1.0819 - Tag_3_loss: 0.6221 - Tag_4_loss: 0.9126 - Tag_0_acc: 0.8494 - Tag_1_acc: 0.7800 - Tag_2_acc: 0.7281 - Tag_3_acc: 0.8712 - Tag_4_acc: 0.8063 - val_loss: 5.3710 - val_Tag_0_loss: 1.0932 - val_Tag_1_loss: 0.9398 - val_Tag_2_loss: 1.0251 - val_Tag_3_loss: 0.8064 - val_Tag_4_loss: 1.5066 - val_Tag_0_acc: 0.7400 - val_Tag_1_acc: 0.7675 - val_Tag_2_acc: 0.7550 - val_Tag_3_acc: 0.8425 - val_Tag_4_acc: 0.7000\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 65s 41ms/step - loss: 4.0190 - Tag_0_loss: 0.7241 - Tag_1_loss: 0.8245 - Tag_2_loss: 1.0638 - Tag_3_loss: 0.5268 - Tag_4_loss: 0.8798 - Tag_0_acc: 0.8513 - Tag_1_acc: 0.7931 - Tag_2_acc: 0.7213 - Tag_3_acc: 0.8975 - Tag_4_acc: 0.8206 - val_loss: 3.8838 - val_Tag_0_loss: 0.6656 - val_Tag_1_loss: 0.8104 - val_Tag_2_loss: 0.9175 - val_Tag_3_loss: 0.6000 - val_Tag_4_loss: 0.8903 - val_Tag_0_acc: 0.8600 - val_Tag_1_acc: 0.8150 - val_Tag_2_acc: 0.7975 - val_Tag_3_acc: 0.8650 - val_Tag_4_acc: 0.8175\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 64s 40ms/step - loss: 3.9646 - Tag_0_loss: 0.7487 - Tag_1_loss: 0.8056 - Tag_2_loss: 1.0231 - Tag_3_loss: 0.5343 - Tag_4_loss: 0.8530 - Tag_0_acc: 0.8513 - Tag_1_acc: 0.8012 - Tag_2_acc: 0.7637 - Tag_3_acc: 0.8850 - Tag_4_acc: 0.8213 - val_loss: 3.8822 - val_Tag_0_loss: 0.6695 - val_Tag_1_loss: 0.8156 - val_Tag_2_loss: 0.9388 - val_Tag_3_loss: 0.6065 - val_Tag_4_loss: 0.8517 - val_Tag_0_acc: 0.8600 - val_Tag_1_acc: 0.8275 - val_Tag_2_acc: 0.7900 - val_Tag_3_acc: 0.8650 - val_Tag_4_acc: 0.8350\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 65s 40ms/step - loss: 3.7074 - Tag_0_loss: 0.6911 - Tag_1_loss: 0.7164 - Tag_2_loss: 1.0176 - Tag_3_loss: 0.4662 - Tag_4_loss: 0.8161 - Tag_0_acc: 0.8606 - Tag_1_acc: 0.8406 - Tag_2_acc: 0.7481 - Tag_3_acc: 0.9038 - Tag_4_acc: 0.8238 - val_loss: 4.6726 - val_Tag_0_loss: 0.8261 - val_Tag_1_loss: 0.8528 - val_Tag_2_loss: 1.0308 - val_Tag_3_loss: 0.6947 - val_Tag_4_loss: 1.2682 - val_Tag_0_acc: 0.8200 - val_Tag_1_acc: 0.7900 - val_Tag_2_acc: 0.7700 - val_Tag_3_acc: 0.8650 - val_Tag_4_acc: 0.7425\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 64s 40ms/step - loss: 3.7872 - Tag_0_loss: 0.7090 - Tag_1_loss: 0.7518 - Tag_2_loss: 1.0042 - Tag_3_loss: 0.5152 - Tag_4_loss: 0.8071 - Tag_0_acc: 0.8575 - Tag_1_acc: 0.8387 - Tag_2_acc: 0.7519 - Tag_3_acc: 0.8900 - Tag_4_acc: 0.8338 - val_loss: 3.9046 - val_Tag_0_loss: 0.6707 - val_Tag_1_loss: 0.8099 - val_Tag_2_loss: 0.9348 - val_Tag_3_loss: 0.5927 - val_Tag_4_loss: 0.8965 - val_Tag_0_acc: 0.8700 - val_Tag_1_acc: 0.7925 - val_Tag_2_acc: 0.7800 - val_Tag_3_acc: 0.8850 - val_Tag_4_acc: 0.8100\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 65s 41ms/step - loss: 3.4699 - Tag_0_loss: 0.6247 - Tag_1_loss: 0.6930 - Tag_2_loss: 0.9907 - Tag_3_loss: 0.4209 - Tag_4_loss: 0.7407 - Tag_0_acc: 0.8769 - Tag_1_acc: 0.8475 - Tag_2_acc: 0.7606 - Tag_3_acc: 0.9206 - Tag_4_acc: 0.8494 - val_loss: 3.5516 - val_Tag_0_loss: 0.6179 - val_Tag_1_loss: 0.7764 - val_Tag_2_loss: 0.8628 - val_Tag_3_loss: 0.4851 - val_Tag_4_loss: 0.8094 - val_Tag_0_acc: 0.8825 - val_Tag_1_acc: 0.8475 - val_Tag_2_acc: 0.7900 - val_Tag_3_acc: 0.8975 - val_Tag_4_acc: 0.8450\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 64s 40ms/step - loss: 3.4234 - Tag_0_loss: 0.6197 - Tag_1_loss: 0.6871 - Tag_2_loss: 0.9657 - Tag_3_loss: 0.4289 - Tag_4_loss: 0.7221 - Tag_0_acc: 0.8762 - Tag_1_acc: 0.8513 - Tag_2_acc: 0.7581 - Tag_3_acc: 0.9169 - Tag_4_acc: 0.8537 - val_loss: 3.5100 - val_Tag_0_loss: 0.5986 - val_Tag_1_loss: 0.7530 - val_Tag_2_loss: 0.8937 - val_Tag_3_loss: 0.4920 - val_Tag_4_loss: 0.7726 - val_Tag_0_acc: 0.8775 - val_Tag_1_acc: 0.8475 - val_Tag_2_acc: 0.8125 - val_Tag_3_acc: 0.8900 - val_Tag_4_acc: 0.8500\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 63s 40ms/step - loss: 3.4119 - Tag_0_loss: 0.6209 - Tag_1_loss: 0.7034 - Tag_2_loss: 0.9476 - Tag_3_loss: 0.4322 - Tag_4_loss: 0.7078 - Tag_0_acc: 0.8750 - Tag_1_acc: 0.8444 - Tag_2_acc: 0.7819 - Tag_3_acc: 0.9150 - Tag_4_acc: 0.8581 - val_loss: 3.3621 - val_Tag_0_loss: 0.5853 - val_Tag_1_loss: 0.7522 - val_Tag_2_loss: 0.8226 - val_Tag_3_loss: 0.4571 - val_Tag_4_loss: 0.7450 - val_Tag_0_acc: 0.8925 - val_Tag_1_acc: 0.8350 - val_Tag_2_acc: 0.8050 - val_Tag_3_acc: 0.9125 - val_Tag_4_acc: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x410e0518>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, [y for y in y_train_List],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          #callbacks=callbacks,\n",
    "          validation_data=(x_test, [y for y in y_test_List]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single neural\n",
    "val_Tag_0_acc: 0.8825 - val_Tag_1_acc: 0.8350 - val_Tag_2_acc: 0.7975 - val_Tag_3_acc: 0.8975 - val_Tag_4_acc: 0.8475\n",
    "#double neural\n",
    "val_Tag_0_acc: 0.8787 - val_Tag_1_acc: 0.8237 - val_Tag_2_acc: 0.7587 - val_Tag_3_acc: 0.8875 - val_Tag_4_acc: 0.8325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single neural softmax\n",
    "(0.8825+0.8350+0.7975+0.8975+0.8475)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362200000000002"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double neural\n",
    "(0.8787+0.8237+0.7587+0.8875+0.8325)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double neural with multitask loss\n",
    "(0.8925+0.8350+0.8050+0.9125+0.8625)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8404999999999999"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8950+0.8275+0.7375+0.9150+0.8275)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.01945499, 0.8940216 ]], dtype=float32),\n",
       " array([[0.01275013, 0.99992716]], dtype=float32),\n",
       " array([[0.74234015, 0.8995152 ]], dtype=float32),\n",
       " array([[0.90993214, 0.11541927]], dtype=float32),\n",
       " array([[0.06273694, 0.97387433]], dtype=float32)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):    \n",
    "    a = x.eval(session=tf.Session())\n",
    "    a[x < 0.5] = 0\n",
    "    a[x >= 0.5] = 1\n",
    "    return K.variable(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-ddb5730ffb98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-615d0868b466>\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'eval'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Greater_8:0' shape=() dtype=bool>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " K.greater(0.01,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.sigmoid(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
